{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from gym import spaces\n",
    "from gym.spaces import Box, Discrete, Tuple\n",
    "\n",
    "class OneHot(gym.Space):\n",
    "    \"\"\"\n",
    "    One-hot space. Used as the observation space.\n",
    "    \"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def sample(self):\n",
    "        return np.random.multinomial(1, [1. / self.n] * self.n)\n",
    "#         return prng.np_random.multinomial(1, [1. / self.n] * self.n)\n",
    "\n",
    "    def contains(self, x):\n",
    "        return isinstance(x, np.ndarray) and \\\n",
    "               x.shape == (self.n, ) and \\\n",
    "               np.all(np.logical_or(x == 0, x == 1)) and \\\n",
    "               np.sum(x) == 1\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return (self.n, )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"OneHot(%d)\" % self.n\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.n == other.n\n",
    "\n",
    "class IteratedMatchingPennies(gym.Env):\n",
    "    \"\"\"\n",
    "    A two-agent environment for the Matching Pennies game.\n",
    "    \"\"\"\n",
    "    NUM_AGENTS = 2\n",
    "    NUM_ACTIONS = 2\n",
    "    NUM_STATES = 5\n",
    "\n",
    "    def __init__(self, max_steps, batch_size=1):\n",
    "        self.max_steps = max_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.payout_mat = np.array([[1, -1],[-1, 1]])\n",
    "        self.action_space = Tuple([\n",
    "            Discrete(self.NUM_ACTIONS) for _ in range(self.NUM_AGENTS)\n",
    "        ])\n",
    "        self.observation_space = Tuple([\n",
    "            OneHot(self.NUM_STATES) for _ in range(self.NUM_AGENTS)\n",
    "        ])\n",
    "        self.available_actions = [\n",
    "            np.ones((batch_size, self.NUM_ACTIONS), dtype=int)\n",
    "            for _ in range(self.NUM_AGENTS)\n",
    "        ]\n",
    "\n",
    "        self.step_count = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.step_count = 0\n",
    "        init_state = np.zeros((self.batch_size, self.NUM_STATES))\n",
    "        init_state[:, -1] = 1\n",
    "        observations = [init_state, init_state]\n",
    "        info = [{'available_actions': aa} for aa in self.available_actions]\n",
    "        return observations, info\n",
    "\n",
    "    def step(self, action):\n",
    "        ac0, ac1 = action\n",
    "\n",
    "        self.step_count += 1\n",
    "\n",
    "        rewards = []\n",
    "        state0 = np.zeros((self.batch_size, self.NUM_STATES))\n",
    "        state1 = np.zeros((self.batch_size, self.NUM_STATES))\n",
    "        for i, (a0, a1) in enumerate(zip(ac0, ac1)):\n",
    "            rewards.append([self.payout_mat[a1][a0], -self.payout_mat[a1][a0]])\n",
    "            state0[i, a0 * 2 + a1] = 1\n",
    "            state1[i, a1 * 2 + a0] = 1\n",
    "        rewards = list(map(np.asarray, zip(*rewards)))\n",
    "        observations = [state0, state1]\n",
    "\n",
    "        done = (self.step_count == self.max_steps)\n",
    "        info = [{'available_actions': aa} for aa in self.available_actions]\n",
    "\n",
    "        return observations, rewards, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixGame(gym.Env):\n",
    "    \"\"\"An environment consisting of a matrix game with stochastic outomes\"\"\"\n",
    "\n",
    "    NUM_ACTIONS = 3\n",
    "    NUM_STATES = NUM_ACTIONS ** 2 + 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        payout_mean=np.array([[10, 5, -5], [0, 0, 5], [20, -5, 0]]),\n",
    "        payout_std=np.array([[0, 0, 0], [0, 0, 0], [0, 20, 20]]),\n",
    "    ):\n",
    "        super(MatrixGame, self).__init__()\n",
    "        self.num_actions = 3\n",
    "        self.action_space = spaces.Tuple(\n",
    "            [spaces.Discrete(self.num_actions) for _ in range(2)]\n",
    "        )\n",
    "        self.observation_space = spaces.Tuple(\n",
    "            [OneHot(self.NUM_STATES) for _ in range(2)]\n",
    "        )\n",
    "        self.payout_mean_matrix = payout_mean\n",
    "        self.payout_std_matrix = payout_std\n",
    "\n",
    "    def step(self, actions):\n",
    "        a0, a1 = actions\n",
    "\n",
    "        reward = [\n",
    "            self.payout_mean_matrix[a0, a1]\n",
    "            + self.payout_std_matrix[a0, a1] * np.random.randn(1)[0],\n",
    "            self.payout_mean_matrix[a1, a0]\n",
    "            + self.payout_std_matrix[a1, a0] * np.random.randn(1)[0],\n",
    "        ]\n",
    "\n",
    "        obs0 = np.zeros(self.NUM_STATES)\n",
    "        obs1 = np.zeros(self.NUM_STATES)\n",
    "        obs0[a0*self.NUM_ACTIONS + a1] = 1\n",
    "        obs1[a1*self.NUM_ACTIONS + a0] = 1\n",
    "        observations = [obs0, obs1]\n",
    "        done = False\n",
    "        return observations, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        init_state = np.zeros(self.NUM_STATES)\n",
    "        init_state[-1] = 1\n",
    "        return [init_state, init_state]\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = IteratedMatchingPennies(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0., 0., 0., 0., 1.]]), array([[0., 0., 0., 0., 1.]])],\n",
       " [{'available_actions': array([[1, 1]])},\n",
       "  {'available_actions': array([[1, 1]])}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_same = [[1], [1]]\n",
    "action_opp = [[0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0., 0., 0., 1., 0.]]), array([[0., 0., 0., 1., 0.]])],\n",
       " [array([1]), array([-1])],\n",
       " False,\n",
       " [{'available_actions': array([[1, 1]])},\n",
       "  {'available_actions': array([[1, 1]])}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[0., 1., 0., 0., 0.]]), array([[0., 0., 1., 0., 0.]])],\n",
       " [array([-1]), array([1])],\n",
       " False,\n",
       " [{'available_actions': array([[1, 1]])},\n",
       "  {'available_actions': array([[1, 1]])}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action_opp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(OneHot(10), OneHot(10))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = Tuple([\n",
    "    Discrete(self.NUM_ACTIONS) for _ in range(self.NUM_AGENTS)\n",
    "])\n",
    "observation_space = Tuple([\n",
    "    OneHot(self.NUM_STATES) for _ in range(self.NUM_AGENTS)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kurtsmith/miniconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "action_space = Box(low=0.0, high=1.0, shape=(2,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MatrixGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10.0 0.0\n",
      "10.0 0.0\n",
      "---\n",
      "0 1\n",
      "5.0 0.0\n",
      "0.0 0.0\n",
      "---\n",
      "0 2\n",
      "-5.0 0.0\n",
      "20.0 0.0\n",
      "---\n",
      "1 0\n",
      "0.0 0.0\n",
      "5.0 0.0\n",
      "---\n",
      "1 1\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "---\n",
      "1 2\n",
      "5.0 0.0\n",
      "-5.275233430071686 20.78611320315357\n",
      "---\n",
      "2 0\n",
      "20.0 0.0\n",
      "-5.0 0.0\n",
      "---\n",
      "2 1\n",
      "-5.056972130293117 19.84767068379404\n",
      "5.0 0.0\n",
      "---\n",
      "2 2\n",
      "1.119900100093821 19.700217218762138\n",
      "0.8560731818707151 19.90109811777382\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test that matrix game gives right rewards \n",
    "n = 1000\n",
    "reward_list = [0]*n\n",
    "for a0 in range(3):\n",
    "    for a1 in range(3):\n",
    "        for i in range(n):\n",
    "            o,r,d,_ = env.step([a0,a1])\n",
    "            reward_list[i] = r\n",
    "        rewards = np.asarray(reward_list)\n",
    "        print(a0, a1)\n",
    "        print(np.mean(rewards[:, 0]), np.std(rewards[:, 0]))\n",
    "        print(np.mean(rewards[:, 1]), np.std(rewards[:, 1]))\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_fn = MatrixGame\n",
    "match_env_list = [game_fn()] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple(Tuple(Discrete(3), Discrete(3)), Tuple(Discrete(3), Discrete(3)), Tuple(Discrete(3), Discrete(3)))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tuple([env.action_space for env in match_env_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4.],\n",
       "       [3., 4., 1., 2.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.concatenate((actions[0,:], actions[1,:])),\n",
    "          np.concatenate((actions[1,:], actions[0,:]))\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = 0.5 * np.ones((2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = np.array([[1],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = np.zeros((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg[:,-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 1. ],\n",
       "       [0.5, 0.5, 0.5, 0.5, 1. ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((ff, gg), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
